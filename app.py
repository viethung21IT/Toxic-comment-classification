import streamlit as st
import joblib
import numpy as np
import pandas as pd
from preprocessing import preprocessing_clean_text

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Toxic Comment Classifier",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

# Load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
@st.cache_resource
def load_model():
    """Load m√¥ h√¨nh v√† pipeline ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán"""
    try:
        model = joblib.load('best_logistic_custom_model.joblib')
        return model
    except Exception as e:
        st.error(f"L·ªói khi load m√¥ h√¨nh: {str(e)}")
        return None

# C√°c nh√£n ƒë·ªôc h·∫°i (6 nh√£n)
LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']

# Ng∆∞·ª°ng t·ªëi ∆∞u cho t·ª´ng nh√£n (ƒë∆∞·ª£c t√¨m t·ª´ validation set)
OPTIMAL_THRESHOLDS = [0.53, 0.73, 0.52, 0.84, 0.52, 0.69]

# M√¥ t·∫£ chi ti·∫øt cho t·ª´ng nh√£n
LABEL_DESCRIPTIONS = {
    'toxic': '‚ò†Ô∏è ƒê·ªôc h·∫°i - B√¨nh lu·∫≠n c√≥ n·ªôi dung ti√™u c·ª±c, g√¢y h·∫°i',
    'severe_toxic': 'üíÄ R·∫•t ƒë·ªôc h·∫°i - B√¨nh lu·∫≠n c·ª±c k·ª≥ x√∫c ph·∫°m, nguy hi·ªÉm',
    'obscene': 'üîû T·ª•c tƒ©u - B√¨nh lu·∫≠n ch·ª©a n·ªôi dung khi√™u d√¢m, t·ª•c tƒ©u',
    'threat': '‚ö†Ô∏è ƒêe d·ªça - B√¨nh lu·∫≠n c√≥ t√≠nh ch·∫•t ƒëe d·ªça, kh·ªßng b·ªë',
    'insult': 'üò† X√∫c ph·∫°m - B√¨nh lu·∫≠n s·ªâ nh·ª•c, l√†m nh·ª•c ng∆∞·ªùi kh√°c',
    'identity_hate': 'üö´ K·ª≥ th·ªã - B√¨nh lu·∫≠n k·ª≥ th·ªã ch·ªßng t·ªôc, t√¥n gi√°o, gi·ªõi t√≠nh'
}

def predict_toxicity(text, model):
    """
    D·ª± ƒëo√°n ƒë·ªô ƒë·ªôc h·∫°i c·ªßa b√¨nh lu·∫≠n
    
    Args:
        text: VƒÉn b·∫£n ƒë·∫ßu v√†o
        model: M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
    
    Returns:
        predictions: Dict ch·ª©a k·∫øt qu·∫£ d·ª± ƒëo√°n
    """
    # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
    cleaned_text = preprocessing_clean_text(text)
    
    # D·ª± ƒëo√°n x√°c su·∫•t
    probas = model.predict_proba([cleaned_text])[0]
    
    # T·∫°o k·∫øt qu·∫£ v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u cho t·ª´ng nh√£n
    results = {}
    for i, label in enumerate(LABELS):
        optimal_threshold = OPTIMAL_THRESHOLDS[i]
        results[label] = {
            'probability': float(probas[i]),
            'threshold': optimal_threshold,
            'is_toxic': bool(probas[i] > optimal_threshold)
        }
    
    return results, cleaned_text

def main():
    # Header
    st.title("üõ°Ô∏è Toxic Comment Classification System")
    st.markdown("### H·ªá th·ªëng ph√¢n lo·∫°i b√¨nh lu·∫≠n ƒë·ªôc h·∫°i v·ªõi 6 nh√£n")
    st.markdown("---")
    
    # Load m√¥ h√¨nh
    model = load_model()
    
    if model is None:
        st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra file 'best_logistic_custom_model.joblib'")
        return
    
    # Sidebar - Th√¥ng tin
    with st.sidebar:
        st.header("‚ÑπTh√¥ng tin m√¥ h√¨nh")
        st.info("M√¥ h√¨nh: Custom Logistic Regression One-vs-Rest")
        
        st.markdown("---")
        st.markdown("### Danh s√°ch nh√£n & Ng∆∞·ª°ng t·ªëi ∆∞u")
        st.markdown("*M·ªói nh√£n c√≥ ng∆∞·ª°ng ri√™ng ƒë∆∞·ª£c t·ªëi ∆∞u t·ª´ t·∫≠p validation*")
        for i, label in enumerate(LABELS):
            st.markdown(f"**{label}**: `{OPTIMAL_THRESHOLDS[i]:.2f}`")
    
    # Main content
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Nh·∫≠p b√¨nh lu·∫≠n")
        
        # Text input
        user_input = st.text_area(
            "Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n lo·∫°i:",
            height=200,
            placeholder="V√≠ d·ª•: This is a great comment!"
        )
        
        # N√∫t ph√¢n t√≠ch
        analyze_button = st.button("üîç Ph√¢n t√≠ch b√¨nh lu·∫≠n", type="primary", use_container_width=True)
    
    with col2:
        st.subheader("K·∫øt qu·∫£ ph√¢n t√≠ch")
        
        if analyze_button and user_input:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                try:
                    # D·ª± ƒëo√°n
                    results, cleaned_text = predict_toxicity(user_input, model)
                    
                    # Hi·ªÉn th·ªã vƒÉn b·∫£n ƒë√£ x·ª≠ l√Ω
                    with st.expander("üîß VƒÉn b·∫£n sau ti·ªÅn x·ª≠ l√Ω"):
                        st.code(cleaned_text)
                    
                    # Ki·ªÉm tra c√≥ nh√£n n√†o v∆∞·ª£t ng∆∞·ª°ng kh√¥ng
                    toxic_labels = [label for label, data in results.items() if data['is_toxic']]
                    
                    if toxic_labels:
                        st.error(f"**C·∫£nh b√°o:** B√¨nh lu·∫≠n n√†y c√≥ d·∫•u hi·ªáu ƒë·ªôc h·∫°i!")
                        st.markdown(f"**Ph√°t hi·ªán {len(toxic_labels)} nh√£n ƒë·ªôc h·∫°i:**")
                        for label in toxic_labels:
                            st.markdown(f"- {LABEL_DESCRIPTIONS[label]}")
                    else:
                        st.success("**B√¨nh lu·∫≠n an to√†n!** Kh√¥ng ph√°t hi·ªán d·∫•u hi·ªáu ƒë·ªôc h·∫°i.")
                    
                    st.markdown("---")
                    st.markdown("### Chi ti·∫øt x√°c su·∫•t t·ª´ng nh√£n")
                    
                    # T·∫°o DataFrame ƒë·ªÉ hi·ªÉn th·ªã
                    df_results = pd.DataFrame([
                        {
                            'Nh√£n': LABEL_DESCRIPTIONS[label],
                            'X√°c su·∫•t': f"{data['probability']:.2%}",
                            'Ng∆∞·ª°ng': f"{data['threshold']:.2f}",
                            'Tr·∫°ng th√°i': 'üî¥ ƒê·ªôc h·∫°i' if data['is_toxic'] else 'üü¢ An to√†n'
                        }
                        for label, data in results.items()
                    ])
                    
                    st.dataframe(df_results, use_container_width=True, hide_index=True)
                    
                    # Bi·ªÉu ƒë·ªì thanh
                    st.markdown("### Bi·ªÉu ƒë·ªì x√°c su·∫•t")
                    chart_data = pd.DataFrame({
                        'Nh√£n': LABELS,
                        'X√°c su·∫•t': [results[label]['probability'] for label in LABELS]
                    })
                    st.bar_chart(chart_data.set_index('Nh√£n'))
                    
                except Exception as e:
                    st.error(f"L·ªói khi ph√¢n t√≠ch: {str(e)}")
        
        elif analyze_button and not user_input:
            st.warning("Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch!")
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <p>üõ°Ô∏è Toxic Comment Classification System | Ph√°t tri·ªÉn b·∫±ng Streamlit</p>
            <p><small>M√¥ h√¨nh: Custom Logistic Regression v·ªõi TF-IDF Vectorizer</small></p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
